{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the CL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/no_dupes_lda_fit5_18.csv')\n",
    "# This has the latest preproc texts\n",
    "df = pd.read_csv('5_22_preproc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14748"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare count and overlap\n",
    "black = df.index[df['high_black'] == True].tolist()\n",
    "white = df.index[df['high_white'] == True].tolist()\n",
    "asian = df.index[df['high_asian'] == True].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2196"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should I remove these from analysis?\n",
    "len(set(black).intersection(set(white)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = sorted(list(set(black).intersection(set(white))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[overlap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12552"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3168"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(black).intersection(set(asian)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(white).intersection(set(asian)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6385"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6208"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "woah, asian & white neighbs have the lowest overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Are titles alone predictive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['listingTitle'], df['high_white'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer()\n",
    "word_vectorizer.fit(X_train)\n",
    "X_train_vectorized = word_vectorizer.transform(X_train)\n",
    "model = LogisticRegression(C=.1).fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict_proba(word_vectorizer.transform(X_test))[:,1]\n",
    "binary_pred = [0 if value <= 0.5 else 1 for value in predictions]\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "print('accuracy: ', accuracy_score(y_test, binary_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not really."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in neighborhood names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/hoods.txt', 'r') as inf:\n",
    "    hoodnames = inf.read().splitlines()\n",
    "    #hoodnames = inf.read()\n",
    "    #hoodnames = re.split(r',\\s*', hoodnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curated list of Seattle-area neighborhoods -- some manually added in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbs = \"\"\"\"'Adams' 'Alki' 'Arbor Heights' 'Atlantic' 'Ballard' 'Belltown' 'Bellevue' Bitter Lake'\n",
    " 'Bothell' 'Bremerton' 'Briarcliff' 'Brighton' 'Broadview' 'Broadway' 'Bryant' 'Capitol Hill' 'Cedar Park'\n",
    " 'Central Business District' 'Columbia City' 'Crown Hill' 'Dunlap'\n",
    " 'East Queen Anne' 'Eastlake' 'Everett' 'Fairmount Park' 'Fauntleroy' 'Federal Way' 'First Hill'\n",
    " 'Fremont' 'Gatewood' 'Genesee' 'Georgetown' 'Green Lake' 'Greenlake' 'Greenwood'\n",
    " 'Haller Lake' 'Harrison/Denny-Blaine' 'High Point' 'Highland Park'\n",
    " 'Holly Park' 'Industrial District' 'Interbay' 'International District' 'Issaquah' 'Kirkland'\n",
    " 'Laurelhurst' 'Lawton Park' 'Leschi' 'Lower Queen Anne' 'Loyal Heights'\n",
    " 'Madison Park' 'Madrona' 'Mann' 'Maple Leaf' 'Matthews Beach'\n",
    " 'Meadowbrook' 'Mid-Beacon Hill' 'Mill Creek' Minor' 'Montlake' 'Mount Baker' 'Newcastle'\n",
    " 'North Admiral' 'North Beach/Blue Ridge' 'North Beacon Hill'\n",
    " 'North College Park' 'North Delridge' 'North Queen Anne' 'Olympic Hills'\n",
    " 'Phinney Ridge' 'Pike-Market' 'Pinehurst' 'Pioneer Square' 'Portage Bay'\n",
    " 'Rainier Beach' 'Ravenna' 'Redmond' 'Renton' 'Riverview' 'Roosevelt' 'Roxhill' 'Seaview'\n",
    " 'Seward Park' 'Shoreline' 'South Beacon Hill' 'South Delridge' 'South Lake Union'\n",
    " 'South Park' 'Southeast Magnolia' 'Stevens' 'Sunset Hill'\n",
    " 'University District' 'U District' 'UDistrict' 'Victory Heights' 'View Ridge' 'Wallingford'\n",
    " 'Wedgwood' 'West Seattle' 'West Queen Anne' 'West Woodland' 'Westlake'\n",
    " 'Whittier Heights' 'Windermere' 'Yesler Terrace'\"\"\".split(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoods = [name.lower() for name in neighbs if re.match(r'\\w+', name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data:\n",
    "- Strip URLs (or.. should map them to '#url' ???)\n",
    "- Map neighborhood names to '#hood'\n",
    "- Tokenize words & punctuation\n",
    "\n",
    "\n",
    "- don't use 'clean_text' yet since it has some preproc errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_pattern = r'(https?:\\/\\/)?(www)?.*[\\r\\n]*'\n",
    "\n",
    "\n",
    "url_pattern = r'(http)?(www)?\\S*(\\.com|\\.net|\\.gov|\\.be|\\.org)\\S*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_pattern = r\"[#\\w'-]+|[.,!?;]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    no_urls = re.sub(url_pattern, '', text)\n",
    "    for hood in hoodnames:\n",
    "        # hood_pattern = r'\\s+{0}\\s+'.format(hood)\n",
    "        #hood_pattern = r' ?'+hood+' ?'\n",
    "        # Match neighborhood mentions surrounded by whitespace and replace with #hood\n",
    "        no_urls = re.sub(r'\\W+{0}\\W+'.format(hood), ' #hood ', no_urls)\n",
    "    no_digits = re.sub(r'\\d+', '', no_urls)\n",
    "    tokenized = re.findall(punctuation_pattern, no_digits)\n",
    "    return ' '.join([word.lower() for word in tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_example = \"this queen anne apartment is really cool !!! 98105 https://blah.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_example = df.loc[0]['body_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess(short_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(long_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in text.lower().split() if word not in hoodnames] for text in df.clean_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preproc to all texts\n",
    "df['preproc_text'] = df['body_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save her for faster loading!\n",
    "df.to_csv('5_22_preproc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & test models.\n",
    "## Split the data into train & test sets\n",
    "## First, binary classif: high white vs not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['preproc_text'], df['high_white'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = word_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "model = LogisticRegression(C=.1).fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(word_vectorizer.transform(X_test))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pred = [0 if value <= 0.5 else 1 for value in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8585733877561657\n",
      "F1 score:  0.7699530516431925\n",
      "accuracy:  0.781389420012747\n"
     ]
    }
   ],
   "source": [
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "print('accuracy: ', accuracy_score(y_test, binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109c720f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='r')\n",
    "ax2.set_ylabel('Threshold',color='r')\n",
    "ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "ax2.set_xlim([fpr[0],fpr[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['rail' 'westwood' 'concierge' 'marymoor' 'mall' 'airport' 'rianna' 'moda'\n",
      " 'aurora' 'harbor' 'riverpark' 'somerset' 'pools' 'jefferson' 'cedar'\n",
      " 'stadiums' 'fountain' 'cleveland' 'borgata' 'grand']\n",
      "\n",
      "Largest Coefs: \n",
      "['country' 'zoo' 'boutiques' 'domaine' 'village' 'esxpt' 'children'\n",
      " 'inglenook' 'bernard' 'woodland' 'volunteer' 'northshore' 'point' 'odin'\n",
      " 'springline' 'waterscape' 'beach' 'locks' 'urbana' 'nw']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(word_vectorizer.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1]\n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-99bf14f60714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mword_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mX_train_vectorized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \"\"\"\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    120\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Five-fold cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "X, y = df['preproc_text'], df['high_white']\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    word_vectorizer.fit(X_train)\n",
    "    X_train_vectorized = word_vectorizer.fit_transform(X_train)\n",
    "    model = LogisticRegression(C=.1).fit(X_train_vectorized, y_train)\n",
    "    predictions = model.predict_proba(word_vectorizer.transform(X_test))[:,1]\n",
    "    binary_pred = [0 if value <= 0.5 else 1 for value in predictions]\n",
    "    print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "    print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "    print('accuracy: ', accuracy_score(y_test, binary_pred))\n",
    "    feature_names = np.array(word_vectorizer.get_feature_names())\n",
    "\n",
    "    # Sort the coefficients from the model\n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "    # Find the 10 smallest and 10 largest coefficients\n",
    "    # The 10 largest coefficients are being indexed using [:-11:-1]\n",
    "    # so the list returned is in order of largest to smallest\n",
    "    print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "    print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remake train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['preproc_text'], df['high_white'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(1,4)).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ngrams = ngram_vectorizer.transform(X_train)\n",
    "# Logistic regression model\n",
    "#model = LogisticRegression(C=.5).fit(X_train_ngrams, y_train)\n",
    "model = LogisticRegression(C=.5, penalty='l2').fit(X_train_ngrams, y_train)\n",
    "predictions = model.predict_proba(ngram_vectorizer.transform(X_test))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pred = [0 if value <= 0.5 else 1 for value in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8898234895546601\n",
      "F1 score:  0.798804780876494\n",
      "accuracy:  0.8068833652007649\n"
     ]
    }
   ],
   "source": [
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "print('accuracy: ', accuracy_score(y_test, binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['mall' 'rail' 'airport' 'light rail' 'concierge' 'south'\n",
      " 'hood university' 'gym' 'shopping' 'center' 'college' 'marymoor'\n",
      " 'th ave hood' 'story' 'south hood' 'section' 'near' 'marymoor park'\n",
      " 'to shopping' 'westwood']\n",
      "\n",
      "Largest Coefs: \n",
      "['uw' 'ave nw' 'children' 'locks' 'hood beach' 'west' 'charming'\n",
      " 'hood ave' 'basement' 'point' 'smoking' 'laundry' 'village' 'on hood'\n",
      " 'deck' 'hood village' 'market' 'shops' 'beach' 'nw']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(ngram_vectorizer.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e905d170475b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_train_vectorized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngram_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    120\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# CV with ngram on high white\n",
    "kf = KFold(n_splits=5)\n",
    "X, y = df['preproc_text'], df['high_white']\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_vectorized = ngram_vectorizer.fit_transform(X_train)\n",
    "    model = LogisticRegression(C=.5).fit(X_train_vectorized, y_train)\n",
    "    predictions = model.predict_proba(ngram_vectorizer.transform(X_test))[:,1]\n",
    "    binary_pred = [0 if value <= 0.5 else 1 for value in predictions]\n",
    "    print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "    print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "    print('accuracy: ', accuracy_score(y_test, binary_pred))\n",
    "    feature_names = np.array(ngram_vectorizer.get_feature_names())\n",
    "\n",
    "    # Sort the coefficients from the model\n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "    # Find the 10 smallest and 10 largest coefficients\n",
    "    # The 10 largest coefficients are being indexed using [:-11:-1]\n",
    "    # so the list returned is in order of largest to smallest\n",
    "    print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "    print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AP note (04/14) The neighborhood names are still not complete enough -_-\n",
    "# also they are still sneaking in somehow... need more work on preproc\n",
    "# 'kirkland' and 'issaquah' are IN the damn hoods list.. why are they still showing up?!\n",
    "# 5/22: updated regex in preproc, does much better now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, that was a binary prediction on high-white; let's see high-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob a faster way to just grab new labels...\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['preproc_text'], df['high_black'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ngrams = ngram_vectorizer.transform(X_train)\n",
    "# Logistic regression model\n",
    "model = LogisticRegression(C=.5).fit(X_train_ngrams, y_train)\n",
    "predictions = model.predict_proba(ngram_vectorizer.transform(X_test))[:,1]\n",
    "\n",
    "\n",
    "#Parameters to try: l1 penalty instead of l2\n",
    "# different regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pred = [0 if value <= 0.5 else 1 for value in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9070896497141245\n",
      "F1 score:  0.7472647702407001\n",
      "accuracy:  0.8527724665391969\n"
     ]
    }
   ],
   "source": [
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "print('accuracy: ', accuracy_score(y_test, binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['nw' 'ne' 'beach' 'uw' 'trails' 'trail' 'school hood' 'hood square'\n",
      " 'newport' 'island' 'courtyard' 'hood trail' 'blocks' 'hood beach' 'old'\n",
      " 'shops' 'hood park' 'car garage' 'ride' 'hardwood floors']\n",
      "\n",
      "Largest Coefs: \n",
      "['gated' 'college' 'freeway' 'hood station' 'aurora' 'golf' 'ave hood'\n",
      " 'north hood' 'rianna' 'station' 'th ave hood' 'mall' 'court' 'south'\n",
      " 'concierge' 'light rail' 'south hood' 'airport' 'hood university' 'rail']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(ngram_vectorizer.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8560934278030323\n",
      "F1 score:  0.6311522872032427\n",
      "accuracy:  0.7970044614404079\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = word_vectorizer.transform(X_train)\n",
    "model = LogisticRegression(C=.1, penalty='l1').fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict_proba(word_vectorizer.transform(X_test))[:,1]\n",
    "binary_pred = [0 if value <= 0.5 else 1 for value in predictions]\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "print('accuracy: ', accuracy_score(y_test, binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['nw' 'newport' 'ne' 'trader' 'winning' 'trails' 'gilman' 'volunteer'\n",
      " 'beach' 'se' 'comprehensive' 'marymoor' 'trail' 'lincoln' 'surrey' 'coin'\n",
      " 'springline' 'urbana' 'september' 'uw']\n",
      "\n",
      "Largest Coefs: \n",
      "['mall' 'cityline' 'swedish' 'hills' 'stadiums' 'cedar' 'aurora' 'olympus'\n",
      " 'helios' 'centennial' 'southcenter' 'sculpture' 'jefferson' 'concierge'\n",
      " 'rail' 'airport' 'westwood' 'rianna' 'harbor' 'moda']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(word_vectorizer.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1627/2060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try SVM..\n",
    "\n",
    "model = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "model.fit(X_train_vectorized,y_train)\n",
    "predicted = model.predict(word_vectorizer.transform(X_test))\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(word_vectorizer.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five-fold cross validation on unigrams\n",
    "kf = KFold(n_splits=5)\n",
    "X, y = df['preproc_text'], df['high_black']\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    word_vectorizer.fit(X_train)\n",
    "    X_train_vectorized = word_vectorizer.fit_transform(X_train)\n",
    "    model = LogisticRegression(C=.5).fit(X_train_vectorized, y_train)\n",
    "    predictions = model.predict_proba(word_vectorizer.transform(X_test))[:,1]\n",
    "    binary_pred = [0 if value <= 0.5 else 1 for value in predictions]\n",
    "    print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "    print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "    print('accuracy: ', accuracy_score(y_test, binary_pred))\n",
    "    feature_names = np.array(word_vectorizer.get_feature_names())\n",
    "\n",
    "    # Sort the coefficients from the model\n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "    print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "    print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8570017743120733\n",
      "F1 score:  0.7233669443226654\n",
      "accuracy:  0.7861016949152543\n",
      "Smallest Coefs:\n",
      "['nw' 'ne' 'hood square' 'uw' 'trails' 'newport' 'se' 'school hood'\n",
      " 'mountains' 'beach' 'shops' 'hood park' 'trail' 'ave nw' 'courtyard'\n",
      " 'square' 'ne hood wa' 'tour today' 'zoo' 'excellent']\n",
      "\n",
      "Largest Coefs: \n",
      "['flooring' 'elliott' 'mall' 'moda' 'olive' 'hood station' 'ave hood'\n",
      " 'harbor' 'pointe' 'th ave hood wa' 'south hood' 'golf' 'station'\n",
      " 'th ave hood' 'concierge' 'court' 'light rail' 'airport'\n",
      " 'hood university' 'rail']\n",
      "AUC:  0.860598941466387\n",
      "F1 score:  0.7143507972665147\n",
      "accuracy:  0.7874576271186441\n",
      "Smallest Coefs:\n",
      "['nw' 'ne' 'uw' 'hood square' 'trails' 'school hood' 'hood park' 'se'\n",
      " 'shops' 'beach' 'island' 'newport' 'square' 'ave nw' 'mountains' 'nw th'\n",
      " 'zoo' 'starting' 'ne hood' 'trail']\n",
      "\n",
      "Largest Coefs: \n",
      "['hood airport' 'south' 'golf course' 'the hood hood' 'community college'\n",
      " 'valley' 'ave hood' 'olive' 'concierge' 'court' 'south hood'\n",
      " 'hood station' 'station' 'pointe' 'th ave hood wa' 'light rail'\n",
      " 'th ave hood' 'hood university' 'airport' 'rail']\n",
      "AUC:  0.8571538507740589\n",
      "F1 score:  0.7303609341825903\n",
      "accuracy:  0.7847457627118644\n",
      "Smallest Coefs:\n",
      "['nw' 'ne' 'uw' 'hood square' 'school hood' 'mountains' 'shops' 'trails'\n",
      " 'hood park' 'newport' 'beach' 'in hood hood' 'square' 'se' 'island'\n",
      " 'hood trail' 'nw th' 'courtyard' 'ave nw' 'excellent']\n",
      "\n",
      "Largest Coefs: \n",
      "['elliott' 'ave hood' 'flooring' 'with large' 'hood station' 'rainier'\n",
      " 'golf' 'south' 'station' 'valley' 'pointe' 'harbor' 'concierge'\n",
      " 'south hood' 'th ave hood wa' 'th ave hood' 'airport' 'hood university'\n",
      " 'light rail' 'rail']\n",
      "AUC:  0.8859655566476079\n",
      "F1 score:  0.7694753577106518\n",
      "accuracy:  0.8033231603933537\n",
      "Smallest Coefs:\n",
      "['nw' 'ne' 'uw' 'hood square' 'square' 'se' 'trails' 'school hood'\n",
      " 'newport' 'island' 'shops' 'beach' 'nw th' 'hood park' 'mountains'\n",
      " 'se hood wa' 'ave nw' 'campus' 'se hood' 'trail']\n",
      "\n",
      "Largest Coefs: \n",
      "['apartment homes' 'moda' 'hood station' 'rianna' 'pointe' 'aurora' 'line'\n",
      " 'concierge' 'station' 'gated' 'harbor' 'valley' 'south hood' 'golf'\n",
      " 'light rail' 'th ave hood wa' 'th ave hood' 'hood university' 'airport'\n",
      " 'rail']\n",
      "AUC:  0.8878456245077312\n",
      "F1 score:  0.7928519328956966\n",
      "accuracy:  0.8073923363852153\n",
      "Smallest Coefs:\n",
      "['nw' 'ne' 'uw' 'hood square' 'trails' 'island' 'square' 'school hood'\n",
      " 'shops' 'se' 'blocks' 'newport' 'off the' 'town center' 'beach' 'ave nw'\n",
      " 'walking' 'hood town center' 'hood park' 'nw th']\n",
      "\n",
      "Largest Coefs: \n",
      "['roof' 'court' 'moda' 'westwood' 'hood station' 'olive' 'west hood'\n",
      " 'golf' 'harbor' 'ave hood' 'city' 'th ave hood wa' 'concierge'\n",
      " 'th ave hood' 'south hood' 'light rail' 'station' 'hood university'\n",
      " 'airport' 'rail']\n"
     ]
    }
   ],
   "source": [
    "# CV with ngram\n",
    "kf = KFold(n_splits=5)\n",
    "X, y = df['preproc_text'], df['high_black']\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_vectorized = ngram_vectorizer.fit_transform(X_train)\n",
    "    model = LogisticRegression(C=.5).fit(X_train_vectorized, y_train)\n",
    "    predictions = model.predict_proba(ngram_vectorizer.transform(X_test))[:,1]\n",
    "    binary_pred = [0 if value <= 0.5 else 1 for value in predictions]\n",
    "    print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "    print('F1 score: ', f1_score(y_test, binary_pred))\n",
    "    print('accuracy: ', accuracy_score(y_test, binary_pred))\n",
    "    feature_names = np.array(ngram_vectorizer.get_feature_names())\n",
    "\n",
    "    # Sort the coefficients from the model\n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "    print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "    print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
